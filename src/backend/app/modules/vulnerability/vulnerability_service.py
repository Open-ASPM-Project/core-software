from typing import Optional, Tuple
from sqlalchemy.future import select
from datetime import datetime, timezone
from typing import List, Optional

from app.modules.incidents.models.incident_model import IncidentTypeEnum, IncidentStatusEnum
from app.modules.incidents.schemas.incident_schemas import IncidentBase
from app.modules.incidents.services.incident_service import create_incident
from app.modules.repository.repository_service import get_repo_by_id, get_repos_by_vc_id
from app.modules.repository.models.repository import Repo
from app.modules.repository.models.repository_scan import RepositoryScan, ScanStatusEnum, RepoScanType
from app.core.logger import logger
from app.modules.slack_integration.slack_integration_service import notify_vulnerabilities
from app.modules.vulnerability.models.vulnerability_model import VulnerabilityType
from app.modules.vc.vc_service import get_vc
from app.utils.clone_repo import clone_repo
from app.utils.vulnerability.grype import run_grype, parse_vulnerabilities
from app.utils.vulnerability.confused import run_confused, parse_confusion_data
from app.modules.user.models.user import User
from app.modules.vulnerability.models.vulnerability_model import Vulnerability
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import func, distinct, asc, desc, or_, cast, String
from app.utils.pagination import paginate
from app.modules.whitelist.whitelist_service import add_whitelist
from app.modules.whitelist.model.whitelist_model import Whitelist
from app.modules.whitelist.schema.whitelist_schema import WhitelistCreate
from typing import Optional, List
from datetime import datetime
from sqlalchemy import select, or_, func, asc, desc, distinct
from sqlalchemy.ext.asyncio import AsyncSession
from math import ceil
from app.modules.whitelist.whitelist_service import is_whitelisted
from app.modules.whitelist.schema.whitelist_schema import WhiteListType
from app.modules.slack_integration.slack_integration_service import fetch_and_notify
from app.utils.delete_folder import delete_folder


async def create_repo_scan(db: AsyncSession, repo_id: int) -> RepositoryScan:
    existing_scan_result = await db.execute(
        select(RepositoryScan)
        .filter(repo_id == RepositoryScan.repository_id,
                RepoScanType.VULNERABILITY == RepositoryScan.scan_type,
                RepositoryScan.status.in_([ScanStatusEnum.PENDING, ScanStatusEnum.IN_PROGRESS]))
        .limit(1)
    )
    existing_scan = existing_scan_result.scalar_one_or_none()

    # if existing_scan:
    #     return None

    scan = RepositoryScan(
        repository_id=repo_id,
        created_at=datetime.utcnow(),
        status=ScanStatusEnum.PENDING,
        scan_type=RepoScanType.VULNERABILITY,
    )
    db.add(scan)
    await db.commit()
    logger.info(f"Created Repo scan {scan}")
    return scan

async def add_vulnerabilities_to_db(
    db: AsyncSession, vulnerabilities: List[Vulnerability], repo_id: int, vc_id: int,
        repo_scan_id: Optional[int] = None,
        pr_id: Optional[int] = None,
        pr_scan_id: Optional[int] = None,
        live_commit_id: Optional[int] = None,
        live_commit_scan_id: Optional[int] = None,
        commit: Optional[str] = None,
        message: Optional[str] = None,
        author: Optional[str] = None,
):
    vulnerabilities_db = []
    vulnerabilities_db_new = []
    print('Adding vulnerabilities', len(vulnerabilities))
    for vulnerability in vulnerabilities:
        # Check if the vulnerability already exists for this repository
        existing_vuln_query = await db.execute(
            select(Vulnerability).filter(
                Vulnerability.vulnerability_id == vulnerability.vulnerability_id,
                Vulnerability.repository_id == repo_id,
                Vulnerability.pr_id == pr_id,
                Vulnerability.live_commit_id == live_commit_id,
            )
        )
        existing_vulns = existing_vuln_query.fetchall()
        existing_vulns = [entry[0] for entry in existing_vulns]

        if len(existing_vulns) > 1:
            logger.warning(
                f"Multiple vulnerabilities found for {vulnerability.vulnerability_id} in repository {repo_id}. Proceeding with the first one.")
            existing_vuln = existing_vulns[0]
        elif existing_vulns:
            existing_vuln = existing_vulns[0]
        else:
            existing_vuln = None

        whitelist_id = await is_whitelisted(db, WhiteListType.VULNERABILITY, vulnerability.vulnerability_id, vulnerability.repository_id, vulnerability.vc_id)
        if not whitelist_id:
            whitelist_id = await is_whitelisted(db, WhiteListType.VULNERABILITY, vulnerability.cve_id, vulnerability.repository_id, vulnerability.vc_id)

        if whitelist_id:
            print('Got whitelist', vulnerability.fix_available)
            vulnerability.whitelisted = True
            vulnerability.whitelist_id = whitelist_id

        if existing_vuln:
            logger.info(f"Updating existing vulnerability {vulnerability.vulnerability_id} for repository {repo_id}.")
            # Update fields if necessary
            existing_vuln.severity = vulnerability.severity.lower()
            existing_vuln.description = vulnerability.description
            existing_vuln.cvss_base_score = vulnerability.cvss_base_score
            existing_vuln.cvss_exploitability_score = vulnerability.cvss_exploitability_score
            existing_vuln.cvss_impact_score = vulnerability.cvss_impact_score
            existing_vuln.fix_available = vulnerability.fix_available
            existing_vuln.package_version = vulnerability.package_version
            existing_vuln.artifact_path = vulnerability.artifact_path
            existing_vuln.updated_at = datetime.utcnow()  # Update timestamp
            existing_vuln.vulnerability_urls = vulnerability.vulnerability_urls
            existing_vuln.cve_urls = vulnerability.cve_urls
            if author:
                existing_vuln.author = author
            if commit:
                existing_vuln.commit = commit

            vulnerabilities_db.append(existing_vuln)
            await db.commit()
        else:
            logger.info(f"Adding vulnerability {vulnerability.vulnerability_id} for repository {repo_id}.")
            # Set repository, scan, and VC IDs for new vulnerability
            vulnerability.repository_id = repo_id
            vulnerability.vc_id = vc_id
            vulnerability.severity = vulnerability.severity.lower()

            if repo_scan_id:
                vulnerability.repository_scan_id = repo_scan_id
            if pr_id:
                vulnerability.pr_id = pr_id
            if pr_scan_id:
                vulnerability.pr_scan_id = pr_scan_id
            if live_commit_id:
                vulnerability.live_commit_id = live_commit_id
            if live_commit_scan_id:
                vulnerability.live_commit_scan_id = live_commit_scan_id
            if author:
                vulnerability.author = author
            if commit:
                vulnerability.commit = commit

            db.add(vulnerability)
            vulnerabilities_db.append(vulnerability)
            vulnerabilities_db_new.append(vulnerability)

            await db.commit()

            print('Added vul in db', vulnerability)

            # create incident
            incident = IncidentBase(
                name=vulnerability.cve_id if vulnerability.cve_id else vulnerability.id,
                type=IncidentTypeEnum.vulnerability,
                status=IncidentStatusEnum.CLOSED if vulnerability.whitelisted else IncidentStatusEnum.OPEN,
                vulnerability_id=vulnerability.id,
            )

            incident = await create_incident(db, incident)
            logger.info(f"incident created {incident.id} {incident.type}")

        if not vulnerability.fix_available:
            print('Fix not available, adding to whitelist')
            whitelist_data = WhitelistCreate(
                type="VULNERABILITY",
                name=vulnerability.vulnerability_id,
                vcs=[vc_id],
                repos=[repo_id],
                comment="Automatically whitelisted due to fix unavailability.",
                active=True,
                global_=False
            )
            new_whitelist = await add_whitelist(db, whitelist_data, current_user=None)

    logger.info(f"Processed {len(vulnerabilities)} vulnerabilities for repository {repo_id}.")
    return vulnerabilities_db, vulnerabilities_db_new


async def get_available_vulnerability_filters(db: AsyncSession) -> dict:
    filters = {
        "filters": [
            {"key": "search", "label": "Search", "type": "text", "searchable": True},
            {"key": "vulnerability_types", "label": "Vulnerability Type", "type": "text", "searchable": True},

            {"key": "repo_ids", "label": "Repositories", "type": "api", "searchable": True},
            {"key": "vc_ids", "label": "Version Control Systems", "type": "api", "searchable": True},
            {"key": "pr_ids", "label": "Pull Requests", "type": "api", "searchable": True},
            {"key": "live_commit_ids", "label": "Live Commit", "type": "api", "searchable": True},

            # Multi-select fields
            {
                "key": "vulnerability_ids",
                "label": "Vulnerability IDs",
                "type": "multi-select",
                "searchable": True
            },
            {
                "key": "cve_ids",
                "label": "CVE IDs",
                "type": "multi-select",
                "searchable": True
            },
            {"key": "fix_available", "label": "Fix Available", "type": "boolean", "searchable": True},
            {
                "key": "severities",
                "label": "Severities",
                "type": "multi-select",
                "searchable": True
            },

            # Date filters
            {"key": "created_after", "label": "Created After", "type": "datetime", "searchable": True},
            {"key": "created_before", "label": "Created Before", "type": "datetime", "searchable": True},

            # Additional vulnerability-specific filters
            {
                "key": "vulnerability_data_source",
                "label": "Vulnerability Data Source",
                "type": "text",
                "searchable": True
            },
            {
                "key": "vulnerability_urls",
                "label": "Vulnerability URLs",
                "type": "multi-select",
                "searchable": True
            },
            {
                "key": "cve_urls",
                "label": "CVE URLs",
                "type": "multi-select",
                "searchable": True
            },
            {
                "key": "cve_data_source",
                "label": "CVE Data Source",
                "type": "text",
                "searchable": True
            },
            {
                "key": "description",
                "label": "Description",
                "type": "text",
                "searchable": True
            },
            {
                "key": "cvss_base_score",
                "label": "CVSS Base Score",
                "type": "number",
                "searchable": True
            },
            {
                "key": "cvss_exploitability_score",
                "label": "CVSS Exploitability Score",
                "type": "number",
                "searchable": True
            },
            {
                "key": "cvss_impact_score",
                "label": "CVSS Impact Score",
                "type": "number",
                "searchable": True
            },
            {
                "key": "package_versions",
                "label": "Package Versions",
                "type": "multi-select",
                "searchable": True
            },
            {
                "key": "artifact_types",
                "label": "Artifact Types",
                "type": "multi-select",
                "searchable": True
            },
            {
                "key": "artifact_paths",
                "label": "Artifact Paths",
                "type": "multi-select",
                "searchable": True
            },
            {
                "key": "packages",
                "label": "Packages",
                "type": "multi-select",
                "searchable": True
            },
            {
                "key": "licenses",
                "label": "Licenses",
                "type": "multi-select",
                "searchable": True
            },

            {"key": "sort_by", "label": "Sort By", "type": "text", "searchable": False},
            {"key": "order_by", "label": "Order By", "type": "text", "searchable": False},
        ]
    }
    return filters

async def get_vulnerability_filter_values(
    db: AsyncSession,
    filter_name: str,
    search: Optional[str] = None,
    page: int = 1,
    page_size: int = 10
) -> dict:
    # Mapping from the UI/filter key (plural) to the actual column name in the Vulnerability model.
    FILTER_COLUMN_MAP = {
        "vulnerability_ids": "vulnerability_id",
        "cve_ids": "cve_id",
        "severities": "severity",
        "artifact_types": "artifact_type",
        "packages": "package",
        "package_versions": "package_version",
        "licenses": "license",
        "vulnerability_data_source": "vulnerability_data_source",
        "vulnerability_urls": "vulnerability_urls",
        "cve_urls": "cve_urls",
        "cve_data_source": "cve_data_source",
        "description": "description",
        "cvss_base_score": "cvss_base_score",
        "cvss_exploitability_score": "cvss_exploitability_score",
        "cvss_impact_score": "cvss_impact_score",
        # For fields like fix_available (boolean) or others, if needed.
    }

    # Determine the actual column name; if not in the map, use the provided name.
    actual_column_name = FILTER_COLUMN_MAP.get(filter_name, filter_name)
    column = getattr(Vulnerability, actual_column_name, None)
    if not column:
        raise ValueError("Invalid filter name")

    query = select(distinct(column)).where(column.isnot(None))

    # For datetime filters, perform special date parsing.
    if filter_name in ["created_after", "created_before"]:
        try:
            search_date = datetime.strptime(search, "%Y-%m-%d") if search else None
        except ValueError:
            raise ValueError("Invalid date format. Use YYYY-MM-DD.")
        if search_date:
            query = query.where(func.date(column) == search_date)
    elif search:
        query = query.where(cast(column, String).ilike(f"%{search}%"))

    total_count = (await db.execute(select(func.count()).select_from(query.subquery()))).scalar()
    paginated_query = query.offset((page - 1) * page_size).limit(page_size)
    result = await db.execute(paginated_query)
    values = [row[0] for row in result.fetchall()]

    def extract_value(item):
        return item.value if hasattr(item, "value") else str(item)

    formatted_values = [{"label": extract_value(value), "value": extract_value(value)} for value in values]

    return {"values": formatted_values, "total": total_count}

async def get_filter_values(db: AsyncSession, filter_name: str, search: Optional[str] = None, page: int = 1, page_size: int = 10) -> Tuple[List[str], int]:
    column = getattr(Vulnerability, filter_name, None)
    if not column:
        raise ValueError("Invalid filter name")

    query = select(distinct(column))
    if search:
        query = query.where(column.ilike(f"%{search}%"))

    paginated_query = paginate(query, await db.scalar(select(func.count()).select_from(query.subquery())), page, page_size)
    result = await db.execute(paginated_query['query'])
    return [row[0] for row in result], paginated_query['meta']['total']


async def get_all_vulnerabilities(
        db: AsyncSession,
        search: Optional[str] = None,
        repo_ids: Optional[List[int]] = None,
        vc_ids: Optional[List[int]] = None,
        pr_ids: Optional[List[int]] = None,
        live_commit_ids: Optional[List[int]] = None,
        vulnerability_ids: Optional[List[str]] = None,
        cve_ids: Optional[List[str]] = None,
        severities: Optional[List[str]] = None,
        created_after: Optional[datetime] = None,
        created_before: Optional[datetime] = None,
        artifact_types: Optional[List[str]] = None,
        packages: Optional[List[str]] = None,
        licenses: Optional[List[str]] = None,
        vulnerability_types: Optional[List[VulnerabilityType]] = None,
        vulnerability_data_source: Optional[str] = None,
        vulnerability_urls: Optional[List[str]] = None,
        cve_urls: Optional[List[str]] = None,
        cve_data_source: Optional[str] = None,
        description: Optional[str] = None,
        cvss_base_score: Optional[float] = None,
        cvss_exploitability_score: Optional[float] = None,
        cvss_impact_score: Optional[float] = None,
        fix_available: Optional[bool] = None,
        page: int = 1,
        limit: int = 10,
        sort_by: str = "created_at",
        order: str = "asc"
) -> dict:
    base_query = select(Vulnerability)

    base_query = select(Vulnerability)

    # 2) Apply filters
    if search:
        base_query = base_query.where(
            or_(
                Vulnerability.vulnerability_id.ilike(f"%{search}%"),
                Vulnerability.cve_id.ilike(f"%{search}%")
            )
        )
    if repo_ids:
        base_query = base_query.where(Vulnerability.repository_id.in_(repo_ids))
    if vc_ids:
        base_query = base_query.where(Vulnerability.vc_id.in_(vc_ids))
    if vulnerability_types:
        base_query = base_query.where(Vulnerability.vulnerability_type.in_(vulnerability_types))
    if pr_ids:
        base_query = base_query.where(Vulnerability.pr_id.in_(pr_ids))
    if live_commit_ids:
        base_query = base_query.where(Vulnerability.live_commit_id.in_(live_commit_ids))

    if vulnerability_ids:
        base_query = base_query.where(Vulnerability.vulnerability_id.in_(vulnerability_ids))
    if cve_ids:
        base_query = base_query.where(Vulnerability.cve_id.in_(cve_ids))
    if severities:
        base_query = base_query.where(Vulnerability.severity.in_(severities))

    if created_after:
        base_query = base_query.where(Vulnerability.created_at >= created_after)
    if created_before:
        base_query = base_query.where(Vulnerability.created_at <= created_before)

    if artifact_types:
        base_query = base_query.where(Vulnerability.artifact_type.in_(artifact_types))
    if packages:
        base_query = base_query.where(Vulnerability.package.in_(packages))
    if licenses:
        base_query = base_query.where(Vulnerability.license.in_(licenses))

    # New filters: vulnerability_data_source, vulnerability_urls, etc.
    if vulnerability_data_source:
        base_query = base_query.where(Vulnerability.vulnerability_data_source == vulnerability_data_source)
    if vulnerability_urls:
        base_query = base_query.where(Vulnerability.vulnerability_urls.in_(vulnerability_urls))
    if cve_urls:
        base_query = base_query.where(Vulnerability.cve_urls.in_(cve_urls))
    if cve_data_source:
        base_query = base_query.where(Vulnerability.cve_data_source == cve_data_source)
    if description:
        base_query = base_query.where(Vulnerability.description.ilike(f"%{description}%"))
    if cvss_base_score is not None:
        base_query = base_query.where(Vulnerability.cvss_base_score == cvss_base_score)
    if cvss_exploitability_score is not None:
        base_query = base_query.where(Vulnerability.cvss_exploitability_score == cvss_exploitability_score)
    if cvss_impact_score is not None:
        base_query = base_query.where(Vulnerability.cvss_impact_score == cvss_impact_score)
    if fix_available is not None:
        base_query = base_query.where(Vulnerability.fix_available == fix_available)

    # Sorting
    order_by_func = asc if order == "asc" else desc
    query = base_query.order_by(order_by_func(getattr(Vulnerability, sort_by)))

    # Pagination
    total_count = await db.scalar(select(func.count()).select_from(query.subquery()))
    paginated_query = paginate(query, total_count, page, limit)
    result = await db.execute(paginated_query['query'])
    vulnerabilities = result.scalars().all()

    return {"data": vulnerabilities,  **paginated_query['meta'] }


async def get_all_unique_vulnerabilities(
        db: AsyncSession,
        search: Optional[str] = None,
        repo_ids: Optional[List[int]] = None,
        vc_ids: Optional[List[int]] = None,
        pr_ids: Optional[List[int]] = None,
        live_commit_ids: Optional[List[int]] = None,
        vulnerability_ids: Optional[List[str]] = None,
        cve_ids: Optional[List[str]] = None,
        severities: Optional[List[str]] = None,
        created_after: Optional[datetime] = None,
        created_before: Optional[datetime] = None,
        artifact_types: Optional[List[str]] = None,
        packages: Optional[List[str]] = None,
        licenses: Optional[List[str]] = None,
        vulnerability_types: Optional[List[VulnerabilityType]] = None,
        vulnerability_data_source: Optional[str] = None,
        vulnerability_urls: Optional[List[str]] = None,
        cve_urls: Optional[List[str]] = None,
        cve_data_source: Optional[str] = None,
        description: Optional[str] = None,
        cvss_base_score: Optional[float] = None,
        cvss_exploitability_score: Optional[float] = None,
        cvss_impact_score: Optional[float] = None,
        fix_available: Optional[bool] = None,
        page: int = 1,
        limit: int = 10,
        sort_by: str = "created_at",
        order: str = "asc"
) -> dict:
    # 1) Base query
    base_query = select(Vulnerability)

    # 2) Apply filters
    if search:
        base_query = base_query.where(
            or_(
                Vulnerability.vulnerability_id.ilike(f"%{search}%"),
                Vulnerability.cve_id.ilike(f"%{search}%")
            )
        )
    if repo_ids:
        base_query = base_query.where(Vulnerability.repository_id.in_(repo_ids))
    if vc_ids:
        base_query = base_query.where(Vulnerability.vc_id.in_(vc_ids))
    if vulnerability_types:
        base_query = base_query.where(Vulnerability.vulnerability_type.in_(vulnerability_types))
    if pr_ids:
        base_query = base_query.where(Vulnerability.pr_id.in_(pr_ids))
    if live_commit_ids:
        base_query = base_query.where(Vulnerability.live_commit_id.in_(live_commit_ids))

    if vulnerability_ids:
        base_query = base_query.where(Vulnerability.vulnerability_id.in_(vulnerability_ids))
    if cve_ids:
        base_query = base_query.where(Vulnerability.cve_id.in_(cve_ids))
    if severities:
        base_query = base_query.where(Vulnerability.severity.in_(severities))

    if created_after:
        base_query = base_query.where(Vulnerability.created_at >= created_after)
    if created_before:
        base_query = base_query.where(Vulnerability.created_at <= created_before)

    if artifact_types:
        base_query = base_query.where(Vulnerability.artifact_type.in_(artifact_types))
    if packages:
        base_query = base_query.where(Vulnerability.package.in_(packages))
    if licenses:
        base_query = base_query.where(Vulnerability.license.in_(licenses))

    # New filters: vulnerability_data_source, vulnerability_urls, etc.
    if vulnerability_data_source:
        base_query = base_query.where(Vulnerability.vulnerability_data_source == vulnerability_data_source)
    if vulnerability_urls:
        base_query = base_query.where(Vulnerability.vulnerability_urls.in_(vulnerability_urls))
    if cve_urls:
        base_query = base_query.where(Vulnerability.cve_urls.in_(cve_urls))
    if cve_data_source:
        base_query = base_query.where(Vulnerability.cve_data_source == cve_data_source)
    if description:
        base_query = base_query.where(Vulnerability.description.ilike(f"%{description}%"))
    if cvss_base_score is not None:
        base_query = base_query.where(Vulnerability.cvss_base_score == cvss_base_score)
    if cvss_exploitability_score is not None:
        base_query = base_query.where(Vulnerability.cvss_exploitability_score == cvss_exploitability_score)
    if cvss_impact_score is not None:
        base_query = base_query.where(Vulnerability.cvss_impact_score == cvss_impact_score)
    if fix_available is not None:
        base_query = base_query.where(Vulnerability.fix_available == fix_available)

    # 3) Subquery of all filtered vulnerabilities
    filtered_subq = base_query.subquery(name="filtered_vulnerabilities")

    # 4) Group by vulnerability_id to get min(id) + repo_count
    aggregator_subq = (
        select(
            filtered_subq.c.vulnerability_id.label("vulnerability_id"),
            func.min(filtered_subq.c.id).label("min_id"),
            func.count(distinct(filtered_subq.c.repository_id)).label("repo_count")
        )
        .group_by(filtered_subq.c.vulnerability_id)
        .subquery(name="aggregator_subq")
    )

    # 5) Build final query
    final_query = (
        select(
            filtered_subq.c.id.label("id"),
            filtered_subq.c.vulnerability_id.label("vulnerability_id"),
            filtered_subq.c.vulnerability_data_source.label("vulnerability_data_source"),
            filtered_subq.c.vulnerability_urls.label("vulnerability_urls"),
            filtered_subq.c.cve_id.label("cve_id"),
            filtered_subq.c.cve_urls.label("cve_urls"),
            filtered_subq.c.cve_data_source.label("cve_data_source"),
            filtered_subq.c.severity.label("severity"),
            filtered_subq.c.description.label("description"),
            filtered_subq.c.cvss_base_score.label("cvss_base_score"),
            filtered_subq.c.cvss_exploitability_score.label("cvss_exploitability_score"),
            filtered_subq.c.cvss_impact_score.label("cvss_impact_score"),
            filtered_subq.c.fix_available.label("fix_available"),
            filtered_subq.c.package.label("package"),
            filtered_subq.c.package_version.label("package_version"),
            filtered_subq.c.artifact_type.label("artifact_type"),
            filtered_subq.c.artifact_path.label("artifact_path"),
            filtered_subq.c.repository_id.label("repository_id"),
            filtered_subq.c.created_at.label("created_at"),
            aggregator_subq.c.repo_count.label("repo_count"),
        )
        .join(aggregator_subq, aggregator_subq.c.min_id == filtered_subq.c.id)
    )

    # 6) Sorting
    order_by_func = asc if order == "asc" else desc
    if sort_by == "repo_count":
        final_query = final_query.order_by(order_by_func(aggregator_subq.c.repo_count))
    else:
        sort_column = getattr(filtered_subq.c, sort_by, filtered_subq.c.created_at)
        final_query = final_query.order_by(order_by_func(sort_column))

    # 7) Count total rows
    total_count = await db.scalar(
        select(func.count()).select_from(final_query.subquery())
    )

    # 8) Pagination
    offset = (page - 1) * limit
    final_query = final_query.limit(limit).offset(offset)

    # 9) Execute
    result = await db.execute(final_query)
    rows = result.fetchall()

    # 10) Transform rows for output
    data = []
    for row in rows:
        data.append({
            "id": row.id,
            "vulnerability_id": row.vulnerability_id,
            "vulnerability_data_source": row.vulnerability_data_source,
            "vulnerability_urls": row.vulnerability_urls,
            "cve_id": row.cve_id,
            "cve_urls": row.cve_urls,
            "cve_data_source": row.cve_data_source,
            "severity": row.severity,
            "description": row.description,
            "cvss_base_score": row.cvss_base_score,
            "cvss_exploitability_score": row.cvss_exploitability_score,
            "cvss_impact_score": row.cvss_impact_score,
            "fix_available": row.fix_available,
            "package": row.package,
            "package_version": row.package_version,
            "artifact_type": row.artifact_type,
            "artifact_path": row.artifact_path,
            "repository_id": row.repository_id,
            "created_at": row.created_at,
            "repo_count": row.repo_count,
        })

    # 11) Pagination metadata
    total_count = total_count or 0
    total_pages = ceil(total_count / limit) if limit else 1

    return {
        "data": data,
        "total_count": total_count,
        "current_page": page,
        "current_limit": limit,
        "total_pages": total_pages,
    }


async def get_repos_for_vulnerability(
    db: AsyncSession,
    vulnerability_id: str,
    page: int = 1,
    limit: int = 10
):
    """
    Fetch all repositories associated with a specific vulnerability in paginated format.
    """
    query_stmt = (
        select(
            Repo.id.label("repo_id"),
            Repo.name.label("repo_name"),
            Repo.repoUrl.label("repo_url"),
            Repo.author.label("author"),
            Repo.other_repo_details.label("other_repo_details")
        )
        .join(Vulnerability, Vulnerability.repository_id == Repo.id)
        .where(Vulnerability.vulnerability_id == vulnerability_id)
        .distinct(Repo.name)  # Ensure repositories are unique by name
        .order_by(Repo.name.asc())
    )

    # Count query for pagination
    count_query = select(func.count().label("total_count")).select_from(query_stmt.subquery())
    total_count = (await db.execute(count_query)).scalar()

    # Pagination logic
    offset = (page - 1) * limit
    query_stmt = query_stmt.offset(offset).limit(limit)

    # Execute the main query
    result = await db.execute(query_stmt)
    repos = result.fetchall()

    # Transform results into a list of dictionaries
    repos_list = [
        {
            "repo_id": row.repo_id,
            "repo_name": row.repo_name,
            "repo_url": row.repo_url,
            "author": row.author,
            "other_repo_details": row.other_repo_details
        }
        for row in repos
    ]

    total_pages = ceil(total_count / limit)

    return {
        "vulnerability_id": vulnerability_id,
        "repositories": repos_list,
        "total_count": total_count,
        "current_limit": limit,
        "current_page": page,
        "total_pages": total_pages,
    }



async def scan_vulnerability_repo_by_id(db: AsyncSession, repo_id, current_user: Optional[User] = None):
    # Get repo
    repo = await get_repo_by_id(db, repo_id)
    if not repo:
        return None

    # Create a repo scan
    repo_scan = await create_repo_scan(db, repo.id)
    if not repo_scan:
        return None

    # Clone a repo
    vc = await get_vc(db, repo.vc_id)
    repo_scan.status = ScanStatusEnum.IN_PROGRESS
    await db.commit()

    # Get branches to run scan from repo
    branches = repo.sca_branches
    if not branches or len(branches) == 0:
        logger.warning(f"No branches found for repository {repo.id}. Defaulting to 'default'.")
        branches = ['default']
    elif len(branches) > 1:
        logger.info(f"Multiple branches found for repository {repo.id}: {branches}. Proceeding with all branches.")

    vulnerabilities_db = []
    vulnerabilities_db_new = []
    severity_count = {}
    for branch in branches:
        try:
            if branch == 'default':
                repo_clone_dir = clone_repo(vc.type.value, repo.repoUrl, vc.token, repo.name)
            else:
                repo_clone_dir = clone_repo(vc.type.value, repo.repoUrl, vc.token, repo.name, branch)

            if not repo_clone_dir:
                continue

            # Run Grype and Confused scans
            grype_data = await run_grype(repo_clone_dir)
            confused_data = await run_confused(repo_clone_dir)

            # Parse vulnerabilities
            vulnerabilities = await parse_vulnerabilities(grype_data)
            confusion_vulnerabilities = await parse_confusion_data(confused_data)

            # Add vulnerabilities to the database
            vulnerabilities.extend(confusion_vulnerabilities)
            vulnerabilities_db, vulnerabilities_db_new = await add_vulnerabilities_to_db(db, vulnerabilities, repo.id, vc.id, repo_scan_id=repo_scan.id)
            for vul in vulnerabilities_db:
                if vul.severity not in severity_count:
                    severity_count[vul.severity]=0
                else:
                    severity_count[vul.severity]+=1

            if vulnerabilities_db_new and len(vulnerabilities_db_new) > 0:
                await fetch_and_notify(db=db, scan_type='repo_scan',repo_id=repo.id, repo_name=repo.name, vul_count=len(vulnerabilities_db), severity_count=severity_count, sec_count=0)
            delete_folder(repo_clone_dir)
        except Exception as e:
            logger.error(f"Error scanning branch {branch}: {e}")
            continue

    # Update scan status to completed
    repo_scan.status = ScanStatusEnum.COMPLETED
    await db.commit()

    return repo_scan


async def scan_vulnerability_pr_scan_id(db: AsyncSession, repo_id, pr_id, pr_scan_id, author):
    repo = await get_repo_by_id(db, repo_id)
    if not repo:
        return None

    vc = await get_vc(db, repo.vc_id)

    branches = repo.sca_branches
    if not branches or len(branches) == 0:
        logger.warning(f"No branches found for repository {repo.id}. Defaulting to 'default'.")
        branches = ['default']
    elif len(branches) > 1:
        logger.info(f"Multiple branches found for repository {repo.id}: {branches}. Proceeding with all branches.")

    vulnerabilities_db = []
    vulnerabilities_db_new = []
    for branch in branches:
        try:
            if branch == 'default':
                repo_clone_dir = clone_repo(vc.type.value, repo.repoUrl, vc.token, repo.name)
            else:
                repo_clone_dir = clone_repo(vc.type.value, repo.repoUrl, vc.token, repo.name, branch)

            if not repo_clone_dir:
                continue

            # Run Grype and Confused scans
            grype_data = await run_grype(repo_clone_dir)
            confused_data = await run_confused(repo_clone_dir)

            # Parse vulnerabilities
            vulnerabilities = await parse_vulnerabilities(grype_data)
            confusion_vulnerabilities = await parse_confusion_data(confused_data)

            # Add vulnerabilities to the database
            vulnerabilities.extend(confusion_vulnerabilities)
            vulnerabilities_db, vulnerabilities_db_new = await add_vulnerabilities_to_db(
                db, vulnerabilities, repo.id, vc.id, pr_id=pr_id, pr_scan_id=pr_scan_id, author=author
            )
            delete_folder(repo_clone_dir)
        except Exception as e:
            logger.error(f"Error scanning branch {branch}: {e}")
            continue
    
    return vulnerabilities_db, vulnerabilities_db_new


async def scan_vulnerability_live_commit_id(db: AsyncSession, repo_id, live_commit_id, live_commit_scan_id, commit, author):
    print('Scanning Live commit scan for vulnerability')

    repo = await get_repo_by_id(db, repo_id)
    if not repo:
        return None

    vc = await get_vc(db, repo.vc_id)

    branches = repo.sca_branches
    if not branches or len(branches) == 0:
        logger.warning(f"No branches found for repository {repo.id}. Defaulting to 'default'.")
        branches = ['default']
    elif len(branches) > 1:
        logger.info(f"Multiple branches found for repository {repo.id}: {branches}. Proceeding with all branches.")

    print(f'Scanning Live commit scan for vulnerability for branches {branches}')

    vulnerabilities_db = []
    vulnerabilities_db_new = []
    for branch in branches:
        try:
            if branch == 'default':
                repo_clone_dir = clone_repo(vc.type.value, repo.repoUrl, vc.token, repo.name)
            else:
                repo_clone_dir = clone_repo(vc.type.value, repo.repoUrl, vc.token, repo.name, branch)

            if not repo_clone_dir:
                continue

            # Run Grype and Confused scans
            grype_data = await run_grype(repo_clone_dir)
            confused_data = await run_confused(repo_clone_dir)

            # Parse vulnerabilities
            vulnerabilities = await parse_vulnerabilities(grype_data)
            confusion_vulnerabilities = await parse_confusion_data(confused_data)

            # Add vulnerabilities to the database
            vulnerabilities.extend(confusion_vulnerabilities)
            vulnerabilities_db, vulnerabilities_db_new = await add_vulnerabilities_to_db(
                db, vulnerabilities, repo.id, vc.id, live_commit_id=live_commit_id, live_commit_scan_id=live_commit_scan_id,
                commit=commit, author=author
            )
            delete_folder(repo_clone_dir)

        except Exception as e:
            logger.error(f"Error scanning branch {branch}: {e}")
            continue
    print(f'Got vulnerability for Live commit scan {len(vulnerabilities_db)}')
    return vulnerabilities_db, vulnerabilities_db_new


async def scan_vulnerability_all_repos_for_vc(db: AsyncSession, vc_id: int, current_user):
    page = 1
    limit = 100
    scans = []

    while True:
        repos = await get_repos_by_vc_id(db, vc_id=vc_id, page=page, limit=limit)
        if not repos["data"]:
            logger.info(f"No more repositories to scan for VC ID {vc_id}. Completed scanning.")
            break

        for repo in repos["data"]:
            try:
                scan = await scan_vulnerability_repo_by_id(db, repo.id, current_user=current_user)
                if scan:
                    scans.append(scan)
            except Exception as e:
                logger.error(f"Error scanning repository {repo.id}: {e}")
        page += 1

    return scans

async def get_vulnerability_by_id(db: AsyncSession, vulnerability_id: int):
    try:
        query = select(Vulnerability).where(Vulnerability.id == vulnerability_id)
        result = await db.execute(query)
        vulnerability = result.scalar_one()
        return vulnerability
    except NoResultFound:
        raise HTTPException(status_code=404, detail="Vulnerability not found")
